{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective :\n",
    "   * so we are having the cleaned data ,the text column(i.e Text and Summary are also Cleaned)\n",
    "   * Now we have to convert these text columns into numbers as model dont work with strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporing necessary library and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading only 5,000 rows\n",
    "df=pd.read_csv(r'D:\\study material\\ML\\Datasets\\amazon-fine-food-reviews\\Reviews_cleaned.csv',nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42511, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>clean_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>product arrived labeled jumbo salted peanut pe...</td>\n",
       "      <td>not advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "      <td>delight say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "0  B001E4KFG0  A3SGXH7AUHU8GW                     1                       1   \n",
       "1  B00813GRG4  A1D87F6ZCVE5NK                     0                       0   \n",
       "2  B000LQOCH0   ABXLMWJIXXAIN                     1                       1   \n",
       "3  B000UA0QIQ  A395BORC6FGVXV                     3                       3   \n",
       "4  B006K2ZZ7K  A1UQRSCLF8GW1T                     0                       0   \n",
       "\n",
       "   Score        Time                                         Clean_Text  \\\n",
       "0      1  1303862400  bought several vitality canned dog food produc...   \n",
       "1      0  1346976000  product arrived labeled jumbo salted peanut pe...   \n",
       "2      1  1219017600  confection around century light pillowy citrus...   \n",
       "3      0  1307923200  looking secret ingredient robitussin believe f...   \n",
       "4      1  1350777600  great taffy great price wide assortment yummy ...   \n",
       "\n",
       "            clean_summary  \n",
       "0  good quality dog food   \n",
       "1         not advertised   \n",
       "2            delight say   \n",
       "3         cough medicine   \n",
       "4            great taffy   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1. Bag of words : \n",
    " * so this is the most common techinique used in text processing where we take all the words and then for each vector give a value 0/1 if it is present.\n",
    " * Easy to use technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=df['Clean_Text']\n",
    "countvect=CountVectorizer(ngram_range=(1,2),min_df=10,max_features=10000)\n",
    "final_vect=countvect.fit_transform(cleaned_data)\n",
    "final_vect=final_vect.toarray()\n",
    "da=pd.DataFrame(data=final_vect,columns=countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able buy</th>\n",
       "      <th>able drink</th>\n",
       "      <th>able eat</th>\n",
       "      <th>able enjoy</th>\n",
       "      <th>able find</th>\n",
       "      <th>able get</th>\n",
       "      <th>able make</th>\n",
       "      <th>able order</th>\n",
       "      <th>...</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip lock</th>\n",
       "      <th>zipfizz</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>ziplock</th>\n",
       "      <th>ziwipeak</th>\n",
       "      <th>zuke</th>\n",
       "      <th>zukes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  able buy  able drink  able eat  able enjoy  able find  \\\n",
       "0        0     0         0           0         0           0          0   \n",
       "1        0     0         0           0         0           0          0   \n",
       "2        0     0         0           0         0           0          0   \n",
       "3        0     0         0           0         0           0          0   \n",
       "4        0     0         0           0         0           0          0   \n",
       "\n",
       "   able get  able make  able order  ...  zinc  zing  zip  zip lock  zipfizz  \\\n",
       "0         0          0           0  ...     0     0    0         0        0   \n",
       "1         0          0           0  ...     0     0    0         0        0   \n",
       "2         0          0           0  ...     0     0    0         0        0   \n",
       "3         0          0           0  ...     0     0    0         0        0   \n",
       "4         0          0           0  ...     0     0    0         0        0   \n",
       "\n",
       "   ziploc  ziplock  ziwipeak  zuke  zukes  \n",
       "0       0        0         0     0      0  \n",
       "1       0        0         0     0      0  \n",
       "2       0        0         0     0      0  \n",
       "3       0        0         0     0      0  \n",
       "4       0        0         0     0      0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tf-Idf \n",
    "* So now we use the tfidf technique in which we find term frequency and inverse frequency for each word in corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10,max_features=10000)\n",
    "final_vect2=tfidf_vect.fit_transform(cleaned_data)\n",
    "final_vect2=final_vect2.toarray()\n",
    "da2=pd.DataFrame(data=final_vect2,columns=countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able buy</th>\n",
       "      <th>able drink</th>\n",
       "      <th>able eat</th>\n",
       "      <th>able enjoy</th>\n",
       "      <th>able find</th>\n",
       "      <th>able get</th>\n",
       "      <th>able make</th>\n",
       "      <th>able order</th>\n",
       "      <th>...</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip lock</th>\n",
       "      <th>zipfizz</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>ziplock</th>\n",
       "      <th>ziwipeak</th>\n",
       "      <th>zuke</th>\n",
       "      <th>zukes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  able buy  able drink  able eat  able enjoy  able find  \\\n",
       "0      0.0   0.0       0.0         0.0       0.0         0.0        0.0   \n",
       "1      0.0   0.0       0.0         0.0       0.0         0.0        0.0   \n",
       "2      0.0   0.0       0.0         0.0       0.0         0.0        0.0   \n",
       "3      0.0   0.0       0.0         0.0       0.0         0.0        0.0   \n",
       "4      0.0   0.0       0.0         0.0       0.0         0.0        0.0   \n",
       "\n",
       "   able get  able make  able order  ...  zinc  zing  zip  zip lock  zipfizz  \\\n",
       "0       0.0        0.0         0.0  ...   0.0   0.0  0.0       0.0      0.0   \n",
       "1       0.0        0.0         0.0  ...   0.0   0.0  0.0       0.0      0.0   \n",
       "2       0.0        0.0         0.0  ...   0.0   0.0  0.0       0.0      0.0   \n",
       "3       0.0        0.0         0.0  ...   0.0   0.0  0.0       0.0      0.0   \n",
       "4       0.0        0.0         0.0  ...   0.0   0.0  0.0       0.0      0.0   \n",
       "\n",
       "   ziploc  ziplock  ziwipeak  zuke  zukes  \n",
       "0     0.0      0.0       0.0   0.0    0.0  \n",
       "1     0.0      0.0       0.0   0.0    0.0  \n",
       "2     0.0      0.0       0.0   0.0    0.0  \n",
       "3     0.0      0.0       0.0   0.0    0.0  \n",
       "4     0.0      0.0       0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-2 vec \n",
    "* training using my own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "list_of_sent=[]\n",
    "for i in df['Clean_Text']:\n",
    "    list_of_sent.append(i.split())\n",
    "\n",
    "w2v_model=Word2Vec(list_of_sent,min_count=5,size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yummy', 0.813718318939209),\n",
       " ('satisfying', 0.8096741437911987),\n",
       " ('delicious', 0.7774248123168945),\n",
       " ('filling', 0.7348397970199585),\n",
       " ('surprisingly', 0.6780767440795898),\n",
       " ('hearty', 0.6744251847267151),\n",
       " ('crisp', 0.6683987379074097),\n",
       " ('good', 0.6575183868408203),\n",
       " ('crunchy', 0.6559920907020569),\n",
       " ('terrific', 0.6499361395835876)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('tasty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 42511/42511 [00:05<00:00, 7511.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# applying average word to vec to convert text into vectors\n",
    "word_vect=[]\n",
    "for sent in tqdm(list_of_sent):\n",
    "    temp=np.zeros(50)\n",
    "    count_words=0\n",
    "    for word in sent:\n",
    "        if word in w2v_model.wv:\n",
    "            temp+=w2v_model.wv[word]\n",
    "            count_words+=1\n",
    "    if count_words:\n",
    "        word_vect.append(temp/count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42511"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect[0:2]\n",
    "len(word_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tsne on bow vectors\n",
    "tsne = TSNE(n_components=2, perplexity=20, learning_rate=100,n_iter=1000)\n",
    "conv_x=tsne.fit_transform(final_vect)\n",
    "pt_for_tsne = np.hstack((conv_x, np.array(df['Score']).reshape(-1,1)))\n",
    "pt_for_tsne_df = pd.DataFrame(data=pt_for_tsne, columns=['x','y','Score'])\n",
    "colors = {0:'red', 1:'blue'}\n",
    "plt.scatter(pt_for_tsne_df['x'], pt_for_tsne_df['y'], c=pt_for_tsne_df['Score'].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tsne on tfidf vectors\n",
    "tsne = TSNE(n_components=2, perplexity=20, learning_rate=200,n_iter=1000)\n",
    "conv_x=tsne.fit_transform(final_vect2)\n",
    "pt_for_tsne = np.hstack((conv_x ,np.array(df['Score']).reshape(-1,1)))\n",
    "pt_for_tsne_df = pd.DataFrame(data=pt_for_tsne, columns=['x','y','Score'])\n",
    "colors = {0:'red', 1:'blue'}\n",
    "plt.scatter(pt_for_tsne_df['x'], pt_for_tsne_df['y'], c=pt_for_tsne_df['Score'].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tsne on avg-word2 vec \n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=20, learning_rate=200,n_iter=1000)\n",
    "x_em=tsne.fit_transform(word_vect)\n",
    "for_tsne = np.hstack((x_em, np.array(df['Score']).reshape(-1,1)))\n",
    "for_tsne_df = pd.DataFrame(data=for_tsne, columns=['Dimension_x','Dimension_y','Score'])\n",
    "colors = {0:'red', 1:'blue'}\n",
    "plt.scatter(for_tsne_df['Dimension_x'], for_tsne_df['Dimension_y'], c=for_tsne_df['Score'].apply(lambda x: colors[x]))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    "* So after seeing this data I could conclude that the data points are clustered together and cannot be easily seprable\n",
    "* So by seeing the plot one can easily say u cannot easily seperate the positive and negative reviews.\n",
    "* If you work with whole data set may be it works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
